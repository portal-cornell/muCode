import gymnasium as gym
from gymnasium import spaces
import numpy as np
import sys
import string

class AnyString(spaces.Text):
    """A space representing any string."""
    def __init__(self, max_length, charset, min_length=1):
        super().__init__(max_length=max_length, charset=charset, min_length=min_length)
    
    def contains(self, x):
        """Check if x is a valid text.
        
        This method overrides checking whether x is contained in the 
        charset to allow for any string.

        Args:
            x (object): The object to check.

        Returns:
            bool: True if x is a valid text, False otherwise.
        """
        return isinstance(x, str) and self.min_length <= len(x) <= self.max_length
    
class MultistepCodeEnv(gym.Env):
    """Gym environment for multi-step code generation tasks."""
    def __init__(self, initial_prompt=None, max_steps=3, eval_mode="local", remote_address=None):
        """
        Initialize the environment.
        
        Args:
            initial_prompt (string): The initial prompt for the code generation task.
            max_steps (int): The maximum number of steps (actions) allowed in an episode.
            eval_mode (string): The evaluation mode for the generated code. Options: "local", "remote".
            remote_address (string): The address of the remote evaluation server.
        """
        super(MultistepCodeEnv, self).__init__()
        assert initial_prompt is not None, "Initial prompt must be provided."
        self.initial_prompt = initial_prompt
        self.max_steps = max_steps
        assert eval_mode in ["local", "remote"], f"Invalid evaluation mode [{eval_mode}]. Choose 'local' or 'remote'."
        self.eval_mode = eval_mode
        self.remote_address = remote_address
        
        # Observation space: a dictionary with the current prompt and feedback
        self.observation_space = spaces.Dict({
            "prompt": AnyString(max_length=sys.maxsize, charset=string.printable),  # The original or updated prompt
            "feedback": spaces.Dict({ # Feedback after evaluating the generated code
                "public": AnyString(min_length=0, max_length=sys.maxsize, charset=string.printable), 
                "private": AnyString(min_length=0, max_length=sys.maxsize, charset=string.printable)  # Private feedback for the generated code
            })
        })
        
        # Action space: a string of any length, representing the code generated by the LLM
        self.action_space = AnyString(max_length=sys.maxsize, charset=string.printable)
        
        # Internal state
        self.current_step = 0
        self.current_prompt = initial_prompt
        self.last_feedback = {"public": "", "private": ""}
        self.last_action = ""
        self.done = False

    def reset(self, seed=None, options={}):
        """
        Reset the environment to the initial state.
        
        Args:
            seed (int): The random seed for the environment.
            options (dict): Optional parameters for the environment.

        Returns:
            dict: The initial observation.
        """
        super().reset(seed=seed)
        self.current_step = 0
        self.current_prompt = self.initial_prompt
        self.last_feedback = {"public": "", "private": ""}
        self.done = False

        if not isinstance(self.current_prompt, str):
            raise ValueError(f"`current_prompt` must be a string. Instead got {self.current_prompt}")
        if not isinstance(self.last_feedback, dict):
            raise ValueError(f"`last_feedback` must be a string. Instead got {self.last_feedback}")
        if not isinstance(self.last_feedback.get("public", ""), str):
            raise ValueError(f"`last_feedback['public']` must be a string. Instead got {self.last_feedback.get('public', '')}")
        if not isinstance(self.last_feedback.get("private", ""), str):
            raise ValueError(f"`last_feedback['private']` must be a string. Instead got {self.last_feedback.get('private', '')}")

        obs = {
            "prompt": self.current_prompt,
            "feedback": self.last_feedback
        }
        info = {}
        return obs, info

    def step(self, action):
        """
        Take an action (generate code) and return the next state, reward, done flag, and info.

        Args:
            action (string): The code generated by the LLM.
        
        Returns:
            tuple: A tuple (observation, reward, done, info)
        """
        if self.done:
            raise ValueError("Environment has already finished. Call reset() to start a new episode.")
        
        # Evaluate the action (code) here
        feedback, reward, success = self.evaluate_code(action)

        # Update the environment state
        self.current_step += 1
        self.last_action = action
        self.last_feedback = feedback
        self.done = self.current_step >= self.max_steps or success
        truncated = False

        observation = {
            "prompt": self.current_prompt,
            "feedback": self.last_feedback
        }
        info = {
            "steps": self.current_step,
            "success": success
        }

        if not isinstance(self.current_prompt, str):
            raise ValueError(f"`current_prompt` must be a string. Instead got {self.current_prompt}")
        if not isinstance(self.last_feedback, dict):
            raise ValueError(f"`last_feedback` must be a dict. Instead got {self.last_feedback}")
        if not isinstance(self.last_feedback.get("public", ""), str):
            raise ValueError(f"`last_feedback['public']` must be a string. Instead got {self.last_feedback.get('public', '')}")
        if not isinstance(self.last_feedback.get("private", ""), str):
            raise ValueError(f"`last_feedback['private']` must be a string. Instead got {self.last_feedback.get('private', '')}")
        
        return observation, reward, self.done, truncated, info

    def _local_evaluate_code(self, code):
        """
        Simulates local code evaluation. Implement custom evaluation logic here.

        Args:
            code (string): The code generated by the LLM.
        
        Returns:
            tuple: A tuple (feedback, reward, success)
        """
        raise NotImplementedError("This method should be implemented in your custom subclass.")

    def _remote_evaluate_code(self, code):
        """
        Simulates remote code evaluation. Implement custom evaluation logic here.

        Args:
            code (string): The code generated by the LLM.
        
        Returns:
            tuple: A tuple (feedback, reward, success)
        """
        raise NotImplementedError("This method should be implemented in your custom subclass.")
    
    def evaluate_code(self, code):
        """
        Simulates code evaluation. Implement custom evaluation logic here.

        Args:
            code (string): The code generated by the LLM.
        
        Returns:
            tuple: A tuple (feedback, reward, success)
        """
        if self.eval_mode == "local":
            feedback, reward, success = self._local_evaluate_code(code)
        elif self.eval_mode == "remote":
            assert self.remote_address is not None, "Remote address is required for remote evaluation."
            raise NotImplementedError()
        self.last_feedback = feedback
        return feedback, reward, success

    def render(self, mode="human"):
        """
        Render the current state of the environment.

        Args:
            mode (str): The mode to render the environment.
        """
        print(f"Step: {self.current_step}\n")
        if self.last_feedback:
            print(f"Action: {self.last_action}\n")
            print(f"Feedback: {self.last_feedback}\n")
        print(f"Prompt: {self.current_prompt}\n")
